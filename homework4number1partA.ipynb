{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x15babf85350>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    'data', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    'data', train=False, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {6: 0, 9: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label])\n",
    "          for img, label in cifar10 \n",
    "          if label in [6, 9]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [6, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "n_out = 2\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                3072,  # <1>\n",
    "                512,   # <2>\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(\n",
    "                512,   # <2>\n",
    "                n_out, # <3>\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                  [1.0, 2.0, 3.0]])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, _ = cifar2[0]\n",
    "\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch = img.view(-1).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4813, 0.5187]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(img_batch)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "_, index = torch.max(out, dim=1)\n",
    "\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.tensor([\n",
    "    [0.6, 0.4],\n",
    "    [0.9, 0.1],\n",
    "    [0.3, 0.7],\n",
    "    [0.2, 0.8],\n",
    "])\n",
    "class_index = torch.tensor([0, 0, 1, 1]).unsqueeze(1)\n",
    "\n",
    "truth = torch.zeros((4,2))\n",
    "truth.scatter_(dim=1, index=class_index, value=1.0)\n",
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def mse(out):\n",
    "    return ((out - truth) ** 2).sum(dim=1).mean()\n",
    "mse(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6000],\n",
       "        [0.9000],\n",
       "        [0.7000],\n",
       "        [0.8000]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.gather(dim=1, index=class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3024])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def likelihood(out):\n",
    "    prod = 1.0\n",
    "    for x in out.gather(dim=1, index=class_index):\n",
    "        prod *= x\n",
    "    return prod\n",
    "\n",
    "likelihood(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1960])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def neg_log_likelihood(out):\n",
    "    return -likelihood(out).log()\n",
    "\n",
    "neg_log_likelihood(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0750, 0.1500, 0.2500, 0.4750])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "out0 = out.clone().detach()\n",
    "out0[0] = torch.tensor([0.9, 0.1]) # more right\n",
    "\n",
    "out2 = out.clone().detach()\n",
    "out2[0] = torch.tensor([0.4, 0.6]) # slightly wrong\n",
    "\n",
    "out3 = out.clone().detach()\n",
    "out3[0] = torch.tensor([0.1, 0.9]) # very wrong\n",
    "\n",
    "mse_comparison = torch.tensor([mse(o) for o in [out0, out, out2, out3]])\n",
    "mse_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-50.0000,   0.0000,  66.6667, 216.6667])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((mse_comparison / mse_comparison[1]) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7905, 1.1960, 1.6015, 2.9878])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll_comparison = torch.tensor([neg_log_likelihood(o) \n",
    "                               for o in [out0, out, out2, out3]])\n",
    "nll_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-33.9016,   0.0000,  33.9016, 149.8121])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((nll_comparison / nll_comparison[1]) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[0.0, 104.0]])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[0.0, 104.0]])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-inf, 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(softmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-104.,    0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(log_softmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8378, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = cifar2[0]\n",
    "\n",
    "out = model(img.view(-1).unsqueeze(0))\n",
    "\n",
    "loss(out, torch.tensor([label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.273059\n",
      "t3: -2.748128652572632\n",
      "Epoch: 1, Loss: 0.267634\n",
      "t3: -4.637125253677368\n",
      "Epoch: 2, Loss: 0.103204\n",
      "t3: -6.512107849121094\n",
      "Epoch: 3, Loss: 0.304981\n",
      "t3: -8.394071817398071\n",
      "Epoch: 4, Loss: 0.193909\n",
      "t3: -10.310943841934204\n",
      "Epoch: 5, Loss: 0.079469\n",
      "t3: -12.195899724960327\n",
      "Epoch: 6, Loss: 0.114009\n",
      "t3: -14.060909509658813\n",
      "Epoch: 7, Loss: 0.055402\n",
      "t3: -15.881039381027222\n",
      "Epoch: 8, Loss: 0.143898\n",
      "t3: -17.71313714981079\n",
      "Epoch: 9, Loss: 0.206610\n",
      "t3: -19.56968092918396\n",
      "Epoch: 10, Loss: 0.187704\n",
      "t3: -21.407308340072632\n",
      "Epoch: 11, Loss: 0.272994\n",
      "t3: -23.24490761756897\n",
      "Epoch: 12, Loss: 0.202973\n",
      "t3: -25.1219425201416\n",
      "Epoch: 13, Loss: 0.267931\n",
      "t3: -26.93010640144348\n",
      "Epoch: 14, Loss: 0.215639\n",
      "t3: -28.75274419784546\n",
      "Epoch: 15, Loss: 0.428310\n",
      "t3: -30.553974390029907\n",
      "Epoch: 16, Loss: 0.206990\n",
      "t3: -32.4110062122345\n",
      "Epoch: 17, Loss: 0.236499\n",
      "t3: -34.242106437683105\n",
      "Epoch: 18, Loss: 0.128360\n",
      "t3: -36.066227197647095\n",
      "Epoch: 19, Loss: 0.151824\n",
      "t3: -37.88735365867615\n",
      "Epoch: 20, Loss: 0.161146\n",
      "t3: -39.72443628311157\n",
      "Epoch: 21, Loss: 0.080049\n",
      "t3: -41.53758478164673\n",
      "Epoch: 22, Loss: 0.218637\n",
      "t3: -43.34774136543274\n",
      "Epoch: 23, Loss: 0.067192\n",
      "t3: -45.12251043319702\n",
      "Epoch: 24, Loss: 0.066998\n",
      "t3: -46.908785820007324\n",
      "Epoch: 25, Loss: 0.106827\n",
      "t3: -48.723928928375244\n",
      "Epoch: 26, Loss: 0.039302\n",
      "t3: -50.56657266616821\n",
      "Epoch: 27, Loss: 0.320639\n",
      "t3: -52.358776330947876\n",
      "Epoch: 28, Loss: 0.070978\n",
      "t3: -54.1998507976532\n",
      "Epoch: 29, Loss: 0.058866\n",
      "t3: -56.04946255683899\n",
      "Epoch: 30, Loss: 0.032351\n",
      "t3: -57.86012864112854\n",
      "Epoch: 31, Loss: 0.052867\n",
      "t3: -59.72070550918579\n",
      "Epoch: 32, Loss: 0.027613\n",
      "t3: -61.53584933280945\n",
      "Epoch: 33, Loss: 0.075750\n",
      "t3: -63.47616934776306\n",
      "Epoch: 34, Loss: 0.026681\n",
      "t3: -66.06279420852661\n",
      "Epoch: 35, Loss: 0.099702\n",
      "t3: -68.69874024391174\n",
      "Epoch: 36, Loss: 0.014963\n",
      "t3: -70.57072973251343\n",
      "Epoch: 37, Loss: 0.040577\n",
      "t3: -72.78580331802368\n",
      "Epoch: 38, Loss: 0.027145\n",
      "t3: -74.88219237327576\n",
      "Epoch: 39, Loss: 0.054135\n",
      "t3: -76.95065879821777\n",
      "Epoch: 40, Loss: 0.090397\n",
      "t3: -79.02119159698486\n",
      "Epoch: 41, Loss: 0.017991\n",
      "t3: -81.41579174995422\n",
      "Epoch: 42, Loss: 0.110922\n",
      "t3: -83.6966986656189\n",
      "Epoch: 43, Loss: 0.013531\n",
      "t3: -86.27976942062378\n",
      "Epoch: 44, Loss: 0.060925\n",
      "t3: -88.28739714622498\n",
      "Epoch: 45, Loss: 0.038116\n",
      "t3: -90.2072594165802\n",
      "Epoch: 46, Loss: 0.045797\n",
      "t3: -92.09820032119751\n",
      "Epoch: 47, Loss: 0.021591\n",
      "t3: -94.02706623077393\n",
      "Epoch: 48, Loss: 0.026159\n",
      "t3: -95.94094395637512\n",
      "Epoch: 49, Loss: 0.018892\n",
      "t3: -97.83687043190002\n",
      "Epoch: 50, Loss: 0.021750\n",
      "t3: -99.68193411827087\n",
      "Epoch: 51, Loss: 0.010823\n",
      "t3: -101.48909783363342\n",
      "Epoch: 52, Loss: 0.007039\n",
      "t3: -103.29028034210205\n",
      "Epoch: 53, Loss: 0.022929\n",
      "t3: -105.1099910736084\n",
      "Epoch: 54, Loss: 0.016131\n",
      "t3: -106.9201431274414\n",
      "Epoch: 55, Loss: 0.016706\n",
      "t3: -108.76221370697021\n",
      "Epoch: 56, Loss: 0.023463\n",
      "t3: -110.67808890342712\n",
      "Epoch: 57, Loss: 0.015562\n",
      "t3: -112.55207467079163\n",
      "Epoch: 58, Loss: 0.022758\n",
      "t3: -114.47792172431946\n",
      "Epoch: 59, Loss: 0.029351\n",
      "t3: -116.68800640106201\n",
      "Epoch: 60, Loss: 0.020810\n",
      "t3: -118.57595562934875\n",
      "Epoch: 61, Loss: 0.008679\n",
      "t3: -120.40904998779297\n",
      "Epoch: 62, Loss: 0.003308\n",
      "t3: -122.2650842666626\n",
      "Epoch: 63, Loss: 0.013589\n",
      "t3: -124.0941903591156\n",
      "Epoch: 64, Loss: 0.005109\n",
      "t3: -125.8973662853241\n",
      "Epoch: 65, Loss: 0.010107\n",
      "t3: -127.70153903961182\n",
      "Epoch: 66, Loss: 0.011050\n",
      "t3: -129.54859590530396\n",
      "Epoch: 67, Loss: 0.009581\n",
      "t3: -131.37975978851318\n",
      "Epoch: 68, Loss: 0.013809\n",
      "t3: -133.1809401512146\n",
      "Epoch: 69, Loss: 0.021178\n",
      "t3: -135.00805187225342\n",
      "Epoch: 70, Loss: 0.006878\n",
      "t3: -136.8321704864502\n",
      "Epoch: 71, Loss: 0.009795\n",
      "t3: -138.66426873207092\n",
      "Epoch: 72, Loss: 0.019120\n",
      "t3: -140.48539662361145\n",
      "Epoch: 73, Loss: 0.005029\n",
      "t3: -142.34841060638428\n",
      "Epoch: 74, Loss: 0.012709\n",
      "t3: -144.17309403419495\n",
      "Epoch: 75, Loss: 0.004834\n",
      "t3: -145.98225331306458\n",
      "Epoch: 76, Loss: 0.032040\n",
      "t3: -147.80138540267944\n",
      "Epoch: 77, Loss: 0.009165\n",
      "t3: -149.63000631332397\n",
      "Epoch: 78, Loss: 0.002904\n",
      "t3: -151.43025469779968\n",
      "Epoch: 79, Loss: 0.003008\n",
      "t3: -153.26733708381653\n",
      "Epoch: 80, Loss: 0.004512\n",
      "t3: -155.08897638320923\n",
      "Epoch: 81, Loss: 0.011185\n",
      "t3: -156.95006465911865\n",
      "Epoch: 82, Loss: 0.008519\n",
      "t3: -158.77071332931519\n",
      "Epoch: 83, Loss: 0.010719\n",
      "t3: -160.59882140159607\n",
      "Epoch: 84, Loss: 0.003275\n",
      "t3: -162.41501641273499\n",
      "Epoch: 85, Loss: 0.014403\n",
      "t3: -164.23918962478638\n",
      "Epoch: 86, Loss: 0.005915\n",
      "t3: -166.06131410598755\n",
      "Epoch: 87, Loss: 0.014668\n",
      "t3: -167.93031358718872\n",
      "Epoch: 88, Loss: 0.009440\n",
      "t3: -169.77637314796448\n",
      "Epoch: 89, Loss: 0.006236\n",
      "t3: -171.56658387184143\n",
      "Epoch: 90, Loss: 0.007247\n",
      "t3: -173.3971996307373\n",
      "Epoch: 91, Loss: 0.014022\n",
      "t3: -175.2442557811737\n",
      "Epoch: 92, Loss: 0.003401\n",
      "t3: -177.03652477264404\n",
      "Epoch: 93, Loss: 0.004419\n",
      "t3: -178.86163854599\n",
      "Epoch: 94, Loss: 0.008505\n",
      "t3: -180.64637446403503\n",
      "Epoch: 95, Loss: 0.004555\n",
      "t3: -182.54237151145935\n",
      "Epoch: 96, Loss: 0.009197\n",
      "t3: -184.38244819641113\n",
      "Epoch: 97, Loss: 0.003148\n",
      "t3: -186.1842005252838\n",
      "Epoch: 98, Loss: 0.006926\n",
      "t3: -187.99535465240479\n",
      "Epoch: 99, Loss: 0.002565\n",
      "t3: -189.81499457359314\n",
      "Epoch: 100, Loss: 0.011847\n",
      "t3: -191.67108345031738\n",
      "Epoch: 101, Loss: 0.003288\n",
      "t3: -193.47126698493958\n",
      "Epoch: 102, Loss: 0.002804\n",
      "t3: -195.32582092285156\n",
      "Epoch: 103, Loss: 0.006404\n",
      "t3: -197.12008953094482\n",
      "Epoch: 104, Loss: 0.000995\n",
      "t3: -198.94420862197876\n",
      "Epoch: 105, Loss: 0.004663\n",
      "t3: -200.75596475601196\n",
      "Epoch: 106, Loss: 0.004955\n",
      "t3: -202.58307266235352\n",
      "Epoch: 107, Loss: 0.004151\n",
      "t3: -204.59568738937378\n",
      "Epoch: 108, Loss: 0.006742\n",
      "t3: -206.53749203681946\n",
      "Epoch: 109, Loss: 0.007177\n",
      "t3: -208.3875412940979\n",
      "Epoch: 110, Loss: 0.001885\n",
      "t3: -210.2535479068756\n",
      "Epoch: 111, Loss: 0.006542\n",
      "t3: -212.08920431137085\n",
      "Epoch: 112, Loss: 0.002169\n",
      "t3: -213.9008731842041\n",
      "Epoch: 113, Loss: 0.003474\n",
      "t3: -215.70210671424866\n",
      "Epoch: 114, Loss: 0.000919\n",
      "t3: -217.59903049468994\n",
      "Epoch: 115, Loss: 0.008596\n",
      "t3: -219.53485131263733\n",
      "Epoch: 116, Loss: 0.004237\n",
      "t3: -221.37991404533386\n",
      "Epoch: 117, Loss: 0.001903\n",
      "t3: -223.21500444412231\n",
      "Epoch: 118, Loss: 0.003768\n",
      "t3: -225.10993432998657\n",
      "Epoch: 119, Loss: 0.009466\n",
      "t3: -226.95556569099426\n",
      "Epoch: 120, Loss: 0.003718\n",
      "t3: -228.76871514320374\n",
      "Epoch: 121, Loss: 0.012214\n",
      "t3: -230.6053659915924\n",
      "Epoch: 122, Loss: 0.007937\n",
      "t3: -232.46239757537842\n",
      "Epoch: 123, Loss: 0.002273\n",
      "t3: -234.31543850898743\n",
      "Epoch: 124, Loss: 0.006511\n",
      "t3: -236.22034239768982\n",
      "Epoch: 125, Loss: 0.004265\n",
      "t3: -238.0624144077301\n",
      "Epoch: 126, Loss: 0.006636\n",
      "t3: -239.8805480003357\n",
      "Epoch: 127, Loss: 0.003417\n",
      "t3: -241.71819734573364\n",
      "Epoch: 128, Loss: 0.003115\n",
      "t3: -243.5602695941925\n",
      "Epoch: 129, Loss: 0.002538\n",
      "t3: -245.38091278076172\n",
      "Epoch: 130, Loss: 0.007799\n",
      "t3: -247.2040822505951\n",
      "Epoch: 131, Loss: 0.004393\n",
      "t3: -249.02671670913696\n",
      "Epoch: 132, Loss: 0.001920\n",
      "t3: -250.86486196517944\n",
      "Epoch: 133, Loss: 0.002423\n",
      "t3: -252.73186659812927\n",
      "Epoch: 134, Loss: 0.002207\n",
      "t3: -254.53555583953857\n",
      "Epoch: 135, Loss: 0.000476\n",
      "t3: -256.3547384738922\n",
      "Epoch: 136, Loss: 0.000725\n",
      "t3: -258.197806596756\n",
      "Epoch: 137, Loss: 0.003067\n",
      "t3: -260.0204493999481\n",
      "Epoch: 138, Loss: 0.004077\n",
      "t3: -261.82367300987244\n",
      "Epoch: 139, Loss: 0.003021\n",
      "t3: -263.6328372955322\n",
      "Epoch: 140, Loss: 0.003197\n",
      "t3: -265.4595181941986\n",
      "Epoch: 141, Loss: 0.002715\n",
      "t3: -267.30557775497437\n",
      "Epoch: 142, Loss: 0.002808\n",
      "t3: -269.15961718559265\n",
      "Epoch: 143, Loss: 0.003029\n",
      "t3: -270.9827380180359\n",
      "Epoch: 144, Loss: 0.001859\n",
      "t3: -272.84131479263306\n",
      "Epoch: 145, Loss: 0.004014\n",
      "t3: -274.6809027194977\n",
      "Epoch: 146, Loss: 0.003295\n",
      "t3: -276.47517228126526\n",
      "Epoch: 147, Loss: 0.001340\n",
      "t3: -278.2653841972351\n",
      "Epoch: 148, Loss: 0.004161\n",
      "t3: -280.08602023124695\n",
      "Epoch: 149, Loss: 0.001004\n",
      "t3: -281.9161765575409\n",
      "Epoch: 150, Loss: 0.001915\n",
      "t3: -283.76722383499146\n",
      "Epoch: 151, Loss: 0.002747\n",
      "t3: -285.53050565719604\n",
      "Epoch: 152, Loss: 0.001478\n",
      "t3: -287.3616087436676\n",
      "Epoch: 153, Loss: 0.003436\n",
      "t3: -289.2261288166046\n",
      "Epoch: 154, Loss: 0.003494\n",
      "t3: -291.0767183303833\n",
      "Epoch: 155, Loss: 0.000561\n",
      "t3: -292.912805557251\n",
      "Epoch: 156, Loss: 0.001583\n",
      "t3: -294.7279486656189\n",
      "Epoch: 157, Loss: 0.005355\n",
      "t3: -296.57458329200745\n",
      "Epoch: 158, Loss: 0.003703\n",
      "t3: -298.43261194229126\n",
      "Epoch: 159, Loss: 0.004322\n",
      "t3: -300.23778796195984\n",
      "Epoch: 160, Loss: 0.001915\n",
      "t3: -302.08982515335083\n",
      "Epoch: 161, Loss: 0.001798\n",
      "t3: -303.91195368766785\n",
      "Epoch: 162, Loss: 0.003807\n",
      "t3: -305.73159289360046\n",
      "Epoch: 163, Loss: 0.003020\n",
      "t3: -307.5328018665314\n",
      "Epoch: 164, Loss: 0.001980\n",
      "t3: -309.3654673099518\n",
      "Epoch: 165, Loss: 0.004530\n",
      "t3: -311.20255064964294\n",
      "Epoch: 166, Loss: 0.001223\n",
      "t3: -312.98732137680054\n",
      "Epoch: 167, Loss: 0.002239\n",
      "t3: -314.7715482711792\n",
      "Epoch: 168, Loss: 0.000604\n",
      "t3: -316.60663747787476\n",
      "Epoch: 169, Loss: 0.002212\n",
      "t3: -318.38388085365295\n",
      "Epoch: 170, Loss: 0.002832\n",
      "t3: -320.2154951095581\n",
      "Epoch: 171, Loss: 0.001276\n",
      "t3: -322.0476460456848\n",
      "Epoch: 172, Loss: 0.000871\n",
      "t3: -324.00042152404785\n",
      "Epoch: 173, Loss: 0.003145\n",
      "t3: -325.8649477958679\n",
      "Epoch: 174, Loss: 0.003459\n",
      "t3: -327.71904706954956\n",
      "Epoch: 175, Loss: 0.003470\n",
      "t3: -329.5426814556122\n",
      "Epoch: 176, Loss: 0.004689\n",
      "t3: -331.3778557777405\n",
      "Epoch: 177, Loss: 0.001240\n",
      "t3: -333.2009816169739\n",
      "Epoch: 178, Loss: 0.002545\n",
      "t3: -335.13082218170166\n",
      "Epoch: 179, Loss: 0.001517\n",
      "t3: -337.29602313041687\n",
      "Epoch: 180, Loss: 0.001269\n",
      "t3: -339.4931421279907\n",
      "Epoch: 181, Loss: 0.004223\n",
      "t3: -341.6543583869934\n",
      "Epoch: 182, Loss: 0.003244\n",
      "t3: -343.5592610836029\n",
      "Epoch: 183, Loss: 0.002836\n",
      "t3: -345.45020151138306\n",
      "Epoch: 184, Loss: 0.002319\n",
      "t3: -347.28229904174805\n",
      "Epoch: 185, Loss: 0.001670\n",
      "t3: -349.12137961387634\n",
      "Epoch: 186, Loss: 0.003763\n",
      "t3: -350.96296548843384\n",
      "Epoch: 187, Loss: 0.002367\n",
      "t3: -352.76819705963135\n",
      "Epoch: 188, Loss: 0.002609\n",
      "t3: -354.60727429389954\n",
      "Epoch: 189, Loss: 0.002206\n",
      "t3: -356.4458599090576\n",
      "Epoch: 190, Loss: 0.002097\n",
      "t3: -358.2360715866089\n",
      "Epoch: 191, Loss: 0.001409\n",
      "t3: -360.0631811618805\n",
      "Epoch: 192, Loss: 0.003740\n",
      "t3: -361.85743618011475\n",
      "Epoch: 193, Loss: 0.005356\n",
      "t3: -363.8511016368866\n",
      "Epoch: 194, Loss: 0.001513\n",
      "t3: -365.91956901550293\n",
      "Epoch: 195, Loss: 0.001480\n",
      "t3: -367.853392124176\n",
      "Epoch: 196, Loss: 0.000380\n",
      "t3: -369.68349528312683\n",
      "Epoch: 197, Loss: 0.000895\n",
      "t3: -371.5081272125244\n",
      "Epoch: 198, Loss: 0.002057\n",
      "t3: -373.3652296066284\n",
      "Epoch: 199, Loss: 0.001732\n",
      "t3: -375.24719405174255\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 4),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 200\n",
    "t1 = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        t2 = time.time()\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t2 = time.time()\n",
    "        t3 = t1 -t2\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "    print (\"t3:\", t3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.311581\n",
      "Epoch: 1, Loss: 0.253266\n",
      "Epoch: 2, Loss: 0.148927\n",
      "Epoch: 3, Loss: 0.173660\n",
      "Epoch: 4, Loss: 0.203652\n",
      "Epoch: 5, Loss: 0.196086\n",
      "Epoch: 6, Loss: 0.166124\n",
      "Epoch: 7, Loss: 0.148210\n",
      "Epoch: 8, Loss: 0.272409\n",
      "Epoch: 9, Loss: 0.360616\n",
      "Epoch: 10, Loss: 0.195339\n",
      "Epoch: 11, Loss: 0.174894\n",
      "Epoch: 12, Loss: 0.120948\n",
      "Epoch: 13, Loss: 0.100845\n",
      "Epoch: 14, Loss: 0.081434\n",
      "Epoch: 15, Loss: 0.253963\n",
      "Epoch: 16, Loss: 0.070082\n",
      "Epoch: 17, Loss: 0.059574\n",
      "Epoch: 18, Loss: 0.240505\n",
      "Epoch: 19, Loss: 0.334050\n",
      "Epoch: 20, Loss: 0.038998\n",
      "Epoch: 21, Loss: 0.190333\n",
      "Epoch: 22, Loss: 0.157580\n",
      "Epoch: 23, Loss: 0.087759\n",
      "Epoch: 24, Loss: 0.134370\n",
      "Epoch: 25, Loss: 0.057698\n",
      "Epoch: 26, Loss: 0.102789\n",
      "Epoch: 27, Loss: 0.053423\n",
      "Epoch: 28, Loss: 0.108020\n",
      "Epoch: 29, Loss: 0.028507\n",
      "Epoch: 30, Loss: 0.090682\n",
      "Epoch: 31, Loss: 0.061485\n",
      "Epoch: 32, Loss: 0.115234\n",
      "Epoch: 33, Loss: 0.037408\n",
      "Epoch: 34, Loss: 0.059182\n",
      "Epoch: 35, Loss: 0.069342\n",
      "Epoch: 36, Loss: 0.078443\n",
      "Epoch: 37, Loss: 0.102015\n",
      "Epoch: 38, Loss: 0.069451\n",
      "Epoch: 39, Loss: 0.031035\n",
      "Epoch: 40, Loss: 0.067115\n",
      "Epoch: 41, Loss: 0.092573\n",
      "Epoch: 42, Loss: 0.117559\n",
      "Epoch: 43, Loss: 0.024117\n",
      "Epoch: 44, Loss: 0.043823\n",
      "Epoch: 45, Loss: 0.056665\n",
      "Epoch: 46, Loss: 0.011071\n",
      "Epoch: 47, Loss: 0.030759\n",
      "Epoch: 48, Loss: 0.021369\n",
      "Epoch: 49, Loss: 0.057567\n",
      "Epoch: 50, Loss: 0.027180\n",
      "Epoch: 51, Loss: 0.011403\n",
      "Epoch: 52, Loss: 0.049328\n",
      "Epoch: 53, Loss: 0.046065\n",
      "Epoch: 54, Loss: 0.015855\n",
      "Epoch: 55, Loss: 0.016958\n",
      "Epoch: 56, Loss: 0.026888\n",
      "Epoch: 57, Loss: 0.014775\n",
      "Epoch: 58, Loss: 0.035053\n",
      "Epoch: 59, Loss: 0.022542\n",
      "Epoch: 60, Loss: 0.019093\n",
      "Epoch: 61, Loss: 0.019744\n",
      "Epoch: 62, Loss: 0.018388\n",
      "Epoch: 63, Loss: 0.024149\n",
      "Epoch: 64, Loss: 0.025590\n",
      "Epoch: 65, Loss: 0.027810\n",
      "Epoch: 66, Loss: 0.007293\n",
      "Epoch: 67, Loss: 0.014857\n",
      "Epoch: 68, Loss: 0.014307\n",
      "Epoch: 69, Loss: 0.006398\n",
      "Epoch: 70, Loss: 0.016419\n",
      "Epoch: 71, Loss: 0.010331\n",
      "Epoch: 72, Loss: 0.011060\n",
      "Epoch: 73, Loss: 0.007180\n",
      "Epoch: 74, Loss: 0.017837\n",
      "Epoch: 75, Loss: 0.011613\n",
      "Epoch: 76, Loss: 0.005449\n",
      "Epoch: 77, Loss: 0.025047\n",
      "Epoch: 78, Loss: 0.008274\n",
      "Epoch: 79, Loss: 0.016818\n",
      "Epoch: 80, Loss: 0.015212\n",
      "Epoch: 81, Loss: 0.010502\n",
      "Epoch: 82, Loss: 0.007715\n",
      "Epoch: 83, Loss: 0.005449\n",
      "Epoch: 84, Loss: 0.007168\n",
      "Epoch: 85, Loss: 0.012908\n",
      "Epoch: 86, Loss: 0.017295\n",
      "Epoch: 87, Loss: 0.012978\n",
      "Epoch: 88, Loss: 0.016443\n",
      "Epoch: 89, Loss: 0.008026\n",
      "Epoch: 90, Loss: 0.004468\n",
      "Epoch: 91, Loss: 0.007814\n",
      "Epoch: 92, Loss: 0.013021\n",
      "Epoch: 93, Loss: 0.007581\n",
      "Epoch: 94, Loss: 0.006693\n",
      "Epoch: 95, Loss: 0.010244\n",
      "Epoch: 96, Loss: 0.013627\n",
      "Epoch: 97, Loss: 0.008726\n",
      "Epoch: 98, Loss: 0.009270\n",
      "Epoch: 99, Loss: 0.001128\n",
      "Epoch: 100, Loss: 0.001800\n",
      "Epoch: 101, Loss: 0.008001\n",
      "Epoch: 102, Loss: 0.003719\n",
      "Epoch: 103, Loss: 0.003286\n",
      "Epoch: 104, Loss: 0.005522\n",
      "Epoch: 105, Loss: 0.006450\n",
      "Epoch: 106, Loss: 0.004845\n",
      "Epoch: 107, Loss: 0.006426\n",
      "Epoch: 108, Loss: 0.006360\n",
      "Epoch: 109, Loss: 0.004011\n",
      "Epoch: 110, Loss: 0.003694\n",
      "Epoch: 111, Loss: 0.003488\n",
      "Epoch: 112, Loss: 0.005551\n",
      "Epoch: 113, Loss: 0.003599\n",
      "Epoch: 114, Loss: 0.003122\n",
      "Epoch: 115, Loss: 0.003951\n",
      "Epoch: 116, Loss: 0.002715\n",
      "Epoch: 117, Loss: 0.004862\n",
      "Epoch: 118, Loss: 0.003607\n",
      "Epoch: 119, Loss: 0.005416\n",
      "Epoch: 120, Loss: 0.007367\n",
      "Epoch: 121, Loss: 0.007363\n",
      "Epoch: 122, Loss: 0.008787\n",
      "Epoch: 123, Loss: 0.005697\n",
      "Epoch: 124, Loss: 0.004622\n",
      "Epoch: 125, Loss: 0.008785\n",
      "Epoch: 126, Loss: 0.006028\n",
      "Epoch: 127, Loss: 0.000530\n",
      "Epoch: 128, Loss: 0.008905\n",
      "Epoch: 129, Loss: 0.003318\n",
      "Epoch: 130, Loss: 0.004746\n",
      "Epoch: 131, Loss: 0.002887\n",
      "Epoch: 132, Loss: 0.004033\n",
      "Epoch: 133, Loss: 0.005573\n",
      "Epoch: 134, Loss: 0.003016\n",
      "Epoch: 135, Loss: 0.001440\n",
      "Epoch: 136, Loss: 0.002803\n",
      "Epoch: 137, Loss: 0.007991\n",
      "Epoch: 138, Loss: 0.003795\n",
      "Epoch: 139, Loss: 0.003643\n",
      "Epoch: 140, Loss: 0.006537\n",
      "Epoch: 141, Loss: 0.005161\n",
      "Epoch: 142, Loss: 0.011917\n",
      "Epoch: 143, Loss: 0.003056\n",
      "Epoch: 144, Loss: 0.004784\n",
      "Epoch: 145, Loss: 0.003192\n",
      "Epoch: 146, Loss: 0.003652\n",
      "Epoch: 147, Loss: 0.008896\n",
      "Epoch: 148, Loss: 0.005109\n",
      "Epoch: 149, Loss: 0.005971\n",
      "Epoch: 150, Loss: 0.001900\n",
      "Epoch: 151, Loss: 0.002786\n",
      "Epoch: 152, Loss: 0.002341\n",
      "Epoch: 153, Loss: 0.002064\n",
      "Epoch: 154, Loss: 0.004131\n",
      "Epoch: 155, Loss: 0.001593\n",
      "Epoch: 156, Loss: 0.001188\n",
      "Epoch: 157, Loss: 0.001091\n",
      "Epoch: 158, Loss: 0.001266\n",
      "Epoch: 159, Loss: 0.001396\n",
      "Epoch: 160, Loss: 0.003012\n",
      "Epoch: 161, Loss: 0.001407\n",
      "Epoch: 162, Loss: 0.002181\n",
      "Epoch: 163, Loss: 0.002861\n",
      "Epoch: 164, Loss: 0.006457\n",
      "Epoch: 165, Loss: 0.000346\n",
      "Epoch: 166, Loss: 0.002646\n",
      "Epoch: 167, Loss: 0.000842\n",
      "Epoch: 168, Loss: 0.002528\n",
      "Epoch: 169, Loss: 0.004940\n",
      "Epoch: 170, Loss: 0.004176\n",
      "Epoch: 171, Loss: 0.004004\n",
      "Epoch: 172, Loss: 0.000848\n",
      "Epoch: 173, Loss: 0.005000\n",
      "Epoch: 174, Loss: 0.001199\n",
      "Epoch: 175, Loss: 0.001787\n",
      "Epoch: 176, Loss: 0.001797\n",
      "Epoch: 177, Loss: 0.002197\n",
      "Epoch: 178, Loss: 0.003983\n",
      "Epoch: 179, Loss: 0.001664\n",
      "Epoch: 180, Loss: 0.002991\n",
      "Epoch: 181, Loss: 0.004029\n",
      "Epoch: 182, Loss: 0.003263\n",
      "Epoch: 183, Loss: 0.004024\n",
      "Epoch: 184, Loss: 0.000909\n",
      "Epoch: 185, Loss: 0.001224\n",
      "Epoch: 186, Loss: 0.002525\n",
      "Epoch: 187, Loss: 0.003277\n",
      "Epoch: 188, Loss: 0.003523\n",
      "Epoch: 189, Loss: 0.002615\n",
      "Epoch: 190, Loss: 0.000661\n",
      "Epoch: 191, Loss: 0.001040\n",
      "Epoch: 192, Loss: 0.002168\n",
      "Epoch: 193, Loss: 0.001582\n",
      "Epoch: 194, Loss: 0.001789\n",
      "Epoch: 195, Loss: 0.002392\n",
      "Epoch: 196, Loss: 0.004174\n",
      "Epoch: 197, Loss: 0.002915\n",
      "Epoch: 198, Loss: 0.002887\n",
      "Epoch: 199, Loss: 0.001710\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128,2),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 200\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.495928\n",
      "Epoch: 1, Loss: 0.437014\n",
      "Epoch: 2, Loss: 0.240798\n",
      "Epoch: 3, Loss: 0.290249\n",
      "Epoch: 4, Loss: 0.107197\n",
      "Epoch: 5, Loss: 0.241871\n",
      "Epoch: 6, Loss: 0.095160\n",
      "Epoch: 7, Loss: 0.180488\n",
      "Epoch: 8, Loss: 0.231711\n",
      "Epoch: 9, Loss: 0.164056\n",
      "Epoch: 10, Loss: 0.230373\n",
      "Epoch: 11, Loss: 0.104626\n",
      "Epoch: 12, Loss: 0.209761\n",
      "Epoch: 13, Loss: 0.302432\n",
      "Epoch: 14, Loss: 0.161054\n",
      "Epoch: 15, Loss: 0.106048\n",
      "Epoch: 16, Loss: 0.209266\n",
      "Epoch: 17, Loss: 0.153772\n",
      "Epoch: 18, Loss: 0.104511\n",
      "Epoch: 19, Loss: 0.078554\n",
      "Epoch: 20, Loss: 0.149169\n",
      "Epoch: 21, Loss: 0.100369\n",
      "Epoch: 22, Loss: 0.358472\n",
      "Epoch: 23, Loss: 0.043414\n",
      "Epoch: 24, Loss: 0.107459\n",
      "Epoch: 25, Loss: 0.079796\n",
      "Epoch: 26, Loss: 0.017831\n",
      "Epoch: 27, Loss: 0.312643\n",
      "Epoch: 28, Loss: 0.048439\n",
      "Epoch: 29, Loss: 0.047229\n",
      "Epoch: 30, Loss: 0.060887\n",
      "Epoch: 31, Loss: 0.054336\n",
      "Epoch: 32, Loss: 0.037971\n",
      "Epoch: 33, Loss: 0.132314\n",
      "Epoch: 34, Loss: 0.065519\n",
      "Epoch: 35, Loss: 0.026809\n",
      "Epoch: 36, Loss: 0.072250\n",
      "Epoch: 37, Loss: 0.024997\n",
      "Epoch: 38, Loss: 0.055148\n",
      "Epoch: 39, Loss: 0.016088\n",
      "Epoch: 40, Loss: 0.034928\n",
      "Epoch: 41, Loss: 0.034584\n",
      "Epoch: 42, Loss: 0.021154\n",
      "Epoch: 43, Loss: 0.127316\n",
      "Epoch: 44, Loss: 0.032286\n",
      "Epoch: 45, Loss: 0.016321\n",
      "Epoch: 46, Loss: 0.037872\n",
      "Epoch: 47, Loss: 0.021484\n",
      "Epoch: 48, Loss: 0.020831\n",
      "Epoch: 49, Loss: 0.036287\n",
      "Epoch: 50, Loss: 0.005319\n",
      "Epoch: 51, Loss: 0.036403\n",
      "Epoch: 52, Loss: 0.003014\n",
      "Epoch: 53, Loss: 0.003483\n",
      "Epoch: 54, Loss: 0.014428\n",
      "Epoch: 55, Loss: 0.029294\n",
      "Epoch: 56, Loss: 0.033623\n",
      "Epoch: 57, Loss: 0.011985\n",
      "Epoch: 58, Loss: 0.010939\n",
      "Epoch: 59, Loss: 0.013702\n",
      "Epoch: 60, Loss: 0.006777\n",
      "Epoch: 61, Loss: 0.019952\n",
      "Epoch: 62, Loss: 0.020621\n",
      "Epoch: 63, Loss: 0.020880\n",
      "Epoch: 64, Loss: 0.004920\n",
      "Epoch: 65, Loss: 0.021706\n",
      "Epoch: 66, Loss: 0.021115\n",
      "Epoch: 67, Loss: 0.015569\n",
      "Epoch: 68, Loss: 0.022821\n",
      "Epoch: 69, Loss: 0.012258\n",
      "Epoch: 70, Loss: 0.012055\n",
      "Epoch: 71, Loss: 0.007578\n",
      "Epoch: 72, Loss: 0.005955\n",
      "Epoch: 73, Loss: 0.007186\n",
      "Epoch: 74, Loss: 0.014864\n",
      "Epoch: 75, Loss: 0.003739\n",
      "Epoch: 76, Loss: 0.011996\n",
      "Epoch: 77, Loss: 0.004451\n",
      "Epoch: 78, Loss: 0.007862\n",
      "Epoch: 79, Loss: 0.006303\n",
      "Epoch: 80, Loss: 0.007311\n",
      "Epoch: 81, Loss: 0.002161\n",
      "Epoch: 82, Loss: 0.007922\n",
      "Epoch: 83, Loss: 0.005238\n",
      "Epoch: 84, Loss: 0.006817\n",
      "Epoch: 85, Loss: 0.025589\n",
      "Epoch: 86, Loss: 0.002658\n",
      "Epoch: 87, Loss: 0.005697\n",
      "Epoch: 88, Loss: 0.007289\n",
      "Epoch: 89, Loss: 0.005817\n",
      "Epoch: 90, Loss: 0.009387\n",
      "Epoch: 91, Loss: 0.007354\n",
      "Epoch: 92, Loss: 0.003129\n",
      "Epoch: 93, Loss: 0.004735\n",
      "Epoch: 94, Loss: 0.001465\n",
      "Epoch: 95, Loss: 0.005402\n",
      "Epoch: 96, Loss: 0.003751\n",
      "Epoch: 97, Loss: 0.004706\n",
      "Epoch: 98, Loss: 0.004226\n",
      "Epoch: 99, Loss: 0.002932\n",
      "Epoch: 100, Loss: 0.007735\n",
      "Epoch: 101, Loss: 0.005418\n",
      "Epoch: 102, Loss: 0.006782\n",
      "Epoch: 103, Loss: 0.004115\n",
      "Epoch: 104, Loss: 0.001538\n",
      "Epoch: 105, Loss: 0.001467\n",
      "Epoch: 106, Loss: 0.001144\n",
      "Epoch: 107, Loss: 0.004166\n",
      "Epoch: 108, Loss: 0.004074\n",
      "Epoch: 109, Loss: 0.005304\n",
      "Epoch: 110, Loss: 0.002566\n",
      "Epoch: 111, Loss: 0.004963\n",
      "Epoch: 112, Loss: 0.003801\n",
      "Epoch: 113, Loss: 0.003731\n",
      "Epoch: 114, Loss: 0.001904\n",
      "Epoch: 115, Loss: 0.002794\n",
      "Epoch: 116, Loss: 0.004552\n",
      "Epoch: 117, Loss: 0.002521\n",
      "Epoch: 118, Loss: 0.005729\n",
      "Epoch: 119, Loss: 0.006961\n",
      "Epoch: 120, Loss: 0.003585\n",
      "Epoch: 121, Loss: 0.006280\n",
      "Epoch: 122, Loss: 0.010460\n",
      "Epoch: 123, Loss: 0.005351\n",
      "Epoch: 124, Loss: 0.004571\n",
      "Epoch: 125, Loss: 0.003431\n",
      "Epoch: 126, Loss: 0.006621\n",
      "Epoch: 127, Loss: 0.006014\n",
      "Epoch: 128, Loss: 0.003818\n",
      "Epoch: 129, Loss: 0.004041\n",
      "Epoch: 130, Loss: 0.000822\n",
      "Epoch: 131, Loss: 0.004055\n",
      "Epoch: 132, Loss: 0.002756\n",
      "Epoch: 133, Loss: 0.001440\n",
      "Epoch: 134, Loss: 0.002740\n",
      "Epoch: 135, Loss: 0.004322\n",
      "Epoch: 136, Loss: 0.002426\n",
      "Epoch: 137, Loss: 0.004788\n",
      "Epoch: 138, Loss: 0.001380\n",
      "Epoch: 139, Loss: 0.003375\n",
      "Epoch: 140, Loss: 0.004077\n",
      "Epoch: 141, Loss: 0.006334\n",
      "Epoch: 142, Loss: 0.003272\n",
      "Epoch: 143, Loss: 0.004970\n",
      "Epoch: 144, Loss: 0.005388\n",
      "Epoch: 145, Loss: 0.002443\n",
      "Epoch: 146, Loss: 0.001483\n",
      "Epoch: 147, Loss: 0.003198\n",
      "Epoch: 148, Loss: 0.001007\n",
      "Epoch: 149, Loss: 0.005570\n",
      "Epoch: 150, Loss: 0.003019\n",
      "Epoch: 151, Loss: 0.001211\n",
      "Epoch: 152, Loss: 0.003552\n",
      "Epoch: 153, Loss: 0.002700\n",
      "Epoch: 154, Loss: 0.003549\n",
      "Epoch: 155, Loss: 0.004171\n",
      "Epoch: 156, Loss: 0.002765\n",
      "Epoch: 157, Loss: 0.001169\n",
      "Epoch: 158, Loss: 0.002500\n",
      "Epoch: 159, Loss: 0.000579\n",
      "Epoch: 160, Loss: 0.002791\n",
      "Epoch: 161, Loss: 0.001865\n",
      "Epoch: 162, Loss: 0.002068\n",
      "Epoch: 163, Loss: 0.001169\n",
      "Epoch: 164, Loss: 0.001682\n",
      "Epoch: 165, Loss: 0.005407\n",
      "Epoch: 166, Loss: 0.002251\n",
      "Epoch: 167, Loss: 0.000437\n",
      "Epoch: 168, Loss: 0.003679\n",
      "Epoch: 169, Loss: 0.001928\n",
      "Epoch: 170, Loss: 0.001921\n",
      "Epoch: 171, Loss: 0.001692\n",
      "Epoch: 172, Loss: 0.002369\n",
      "Epoch: 173, Loss: 0.004309\n",
      "Epoch: 174, Loss: 0.000929\n",
      "Epoch: 175, Loss: 0.001715\n",
      "Epoch: 176, Loss: 0.002194\n",
      "Epoch: 177, Loss: 0.001467\n",
      "Epoch: 178, Loss: 0.001303\n",
      "Epoch: 179, Loss: 0.001990\n",
      "Epoch: 180, Loss: 0.001766\n",
      "Epoch: 181, Loss: 0.001683\n",
      "Epoch: 182, Loss: 0.001277\n",
      "Epoch: 183, Loss: 0.000490\n",
      "Epoch: 184, Loss: 0.001553\n",
      "Epoch: 185, Loss: 0.002142\n",
      "Epoch: 186, Loss: 0.001750\n",
      "Epoch: 187, Loss: 0.000521\n",
      "Epoch: 188, Loss: 0.001784\n",
      "Epoch: 189, Loss: 0.001466\n",
      "Epoch: 190, Loss: 0.001195\n",
      "Epoch: 191, Loss: 0.002362\n",
      "Epoch: 192, Loss: 0.000051\n",
      "Epoch: 193, Loss: 0.001108\n",
      "Epoch: 194, Loss: 0.001331\n",
      "Epoch: 195, Loss: 0.004118\n",
      "Epoch: 196, Loss: 0.000624\n",
      "Epoch: 197, Loss: 0.001875\n",
      "Epoch: 198, Loss: 0.001575\n",
      "Epoch: 199, Loss: 0.002367\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 200\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.910000\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2),\n",
    "            nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2))\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.243899\n",
      "Epoch: 1, Loss: 0.322556\n",
      "Epoch: 2, Loss: 0.554614\n",
      "Epoch: 3, Loss: 0.205421\n",
      "Epoch: 4, Loss: 0.146262\n",
      "Epoch: 5, Loss: 0.204681\n",
      "Epoch: 6, Loss: 0.109278\n",
      "Epoch: 7, Loss: 0.166629\n",
      "Epoch: 8, Loss: 0.116716\n",
      "Epoch: 9, Loss: 0.520668\n",
      "Epoch: 10, Loss: 0.104574\n",
      "Epoch: 11, Loss: 0.095384\n",
      "Epoch: 12, Loss: 0.082692\n",
      "Epoch: 13, Loss: 0.129466\n",
      "Epoch: 14, Loss: 0.405595\n",
      "Epoch: 15, Loss: 0.040573\n",
      "Epoch: 16, Loss: 0.044479\n",
      "Epoch: 17, Loss: 0.064385\n",
      "Epoch: 18, Loss: 0.266587\n",
      "Epoch: 19, Loss: 0.606524\n",
      "Epoch: 20, Loss: 0.049630\n",
      "Epoch: 21, Loss: 0.228701\n",
      "Epoch: 22, Loss: 0.152616\n",
      "Epoch: 23, Loss: 0.023880\n",
      "Epoch: 24, Loss: 0.106237\n",
      "Epoch: 25, Loss: 0.019835\n",
      "Epoch: 26, Loss: 0.152911\n",
      "Epoch: 27, Loss: 0.226336\n",
      "Epoch: 28, Loss: 0.010262\n",
      "Epoch: 29, Loss: 0.105385\n",
      "Epoch: 30, Loss: 0.002569\n",
      "Epoch: 31, Loss: 0.123275\n",
      "Epoch: 32, Loss: 0.073301\n",
      "Epoch: 33, Loss: 0.015930\n",
      "Epoch: 34, Loss: 0.036814\n",
      "Epoch: 35, Loss: 0.010538\n",
      "Epoch: 36, Loss: 0.005881\n",
      "Epoch: 37, Loss: 0.008337\n",
      "Epoch: 38, Loss: 0.007918\n",
      "Epoch: 39, Loss: 0.002864\n",
      "Epoch: 40, Loss: 0.010769\n",
      "Epoch: 41, Loss: 0.001847\n",
      "Epoch: 42, Loss: 0.002846\n",
      "Epoch: 43, Loss: 0.010272\n",
      "Epoch: 44, Loss: 0.000321\n",
      "Epoch: 45, Loss: 0.008350\n",
      "Epoch: 46, Loss: 0.003287\n",
      "Epoch: 47, Loss: 0.001003\n",
      "Epoch: 48, Loss: 0.001740\n",
      "Epoch: 49, Loss: 0.001588\n",
      "Epoch: 50, Loss: 0.001019\n",
      "Epoch: 51, Loss: 0.000936\n",
      "Epoch: 52, Loss: 0.002202\n",
      "Epoch: 53, Loss: 0.000903\n",
      "Epoch: 54, Loss: 0.002344\n",
      "Epoch: 55, Loss: 0.000237\n",
      "Epoch: 56, Loss: 0.001876\n",
      "Epoch: 57, Loss: 0.000599\n",
      "Epoch: 58, Loss: 0.000510\n",
      "Epoch: 59, Loss: 0.000948\n",
      "Epoch: 60, Loss: 0.002147\n",
      "Epoch: 61, Loss: 0.001687\n",
      "Epoch: 62, Loss: 0.000559\n",
      "Epoch: 63, Loss: 0.001336\n",
      "Epoch: 64, Loss: 0.000693\n",
      "Epoch: 65, Loss: 0.000307\n",
      "Epoch: 66, Loss: 0.000849\n",
      "Epoch: 67, Loss: 0.001143\n",
      "Epoch: 68, Loss: 0.001368\n",
      "Epoch: 69, Loss: 0.000427\n",
      "Epoch: 70, Loss: 0.000327\n",
      "Epoch: 71, Loss: 0.001735\n",
      "Epoch: 72, Loss: 0.000408\n",
      "Epoch: 73, Loss: 0.000156\n",
      "Epoch: 74, Loss: 0.002070\n",
      "Epoch: 75, Loss: 0.000313\n",
      "Epoch: 76, Loss: 0.000993\n",
      "Epoch: 77, Loss: 0.000739\n",
      "Epoch: 78, Loss: 0.001148\n",
      "Epoch: 79, Loss: 0.000594\n",
      "Epoch: 80, Loss: 0.000423\n",
      "Epoch: 81, Loss: 0.000515\n",
      "Epoch: 82, Loss: 0.000406\n",
      "Epoch: 83, Loss: 0.000341\n",
      "Epoch: 84, Loss: 0.000481\n",
      "Epoch: 85, Loss: 0.000552\n",
      "Epoch: 86, Loss: 0.000613\n",
      "Epoch: 87, Loss: 0.000324\n",
      "Epoch: 88, Loss: 0.000387\n",
      "Epoch: 89, Loss: 0.000524\n",
      "Epoch: 90, Loss: 0.000837\n",
      "Epoch: 91, Loss: 0.000381\n",
      "Epoch: 92, Loss: 0.000243\n",
      "Epoch: 93, Loss: 0.000361\n",
      "Epoch: 94, Loss: 0.000673\n",
      "Epoch: 95, Loss: 0.000797\n",
      "Epoch: 96, Loss: 0.000157\n",
      "Epoch: 97, Loss: 0.000095\n",
      "Epoch: 98, Loss: 0.000020\n",
      "Epoch: 99, Loss: 0.000332\n",
      "Epoch: 100, Loss: 0.000101\n",
      "Epoch: 101, Loss: 0.000638\n",
      "Epoch: 102, Loss: 0.001223\n",
      "Epoch: 103, Loss: 0.000596\n",
      "Epoch: 104, Loss: 0.000358\n",
      "Epoch: 105, Loss: 0.000147\n",
      "Epoch: 106, Loss: 0.000312\n",
      "Epoch: 107, Loss: 0.000069\n",
      "Epoch: 108, Loss: 0.000247\n",
      "Epoch: 109, Loss: 0.000315\n",
      "Epoch: 110, Loss: 0.000581\n",
      "Epoch: 111, Loss: 0.000122\n",
      "Epoch: 112, Loss: 0.000215\n",
      "Epoch: 113, Loss: 0.000185\n",
      "Epoch: 114, Loss: 0.000122\n",
      "Epoch: 115, Loss: 0.000265\n",
      "Epoch: 116, Loss: 0.000275\n",
      "Epoch: 117, Loss: 0.000349\n",
      "Epoch: 118, Loss: 0.000450\n",
      "Epoch: 119, Loss: 0.000107\n",
      "Epoch: 120, Loss: 0.000456\n",
      "Epoch: 121, Loss: 0.000229\n",
      "Epoch: 122, Loss: 0.000483\n",
      "Epoch: 123, Loss: 0.000048\n",
      "Epoch: 124, Loss: 0.000552\n",
      "Epoch: 125, Loss: 0.000400\n",
      "Epoch: 126, Loss: 0.000231\n",
      "Epoch: 127, Loss: 0.000081\n",
      "Epoch: 128, Loss: 0.000233\n",
      "Epoch: 129, Loss: 0.000039\n",
      "Epoch: 130, Loss: 0.000218\n",
      "Epoch: 131, Loss: 0.000121\n",
      "Epoch: 132, Loss: 0.000171\n",
      "Epoch: 133, Loss: 0.000223\n",
      "Epoch: 134, Loss: 0.000270\n",
      "Epoch: 135, Loss: 0.000018\n",
      "Epoch: 136, Loss: 0.000130\n",
      "Epoch: 137, Loss: 0.000031\n",
      "Epoch: 138, Loss: 0.000175\n",
      "Epoch: 139, Loss: 0.000175\n",
      "Epoch: 140, Loss: 0.000065\n",
      "Epoch: 141, Loss: 0.000361\n",
      "Epoch: 142, Loss: 0.000120\n",
      "Epoch: 143, Loss: 0.000351\n",
      "Epoch: 144, Loss: 0.000186\n",
      "Epoch: 145, Loss: 0.000106\n",
      "Epoch: 146, Loss: 0.000152\n",
      "Epoch: 147, Loss: 0.000028\n",
      "Epoch: 148, Loss: 0.000135\n",
      "Epoch: 149, Loss: 0.000195\n",
      "Epoch: 150, Loss: 0.000493\n",
      "Epoch: 151, Loss: 0.000099\n",
      "Epoch: 152, Loss: 0.000036\n",
      "Epoch: 153, Loss: 0.000201\n",
      "Epoch: 154, Loss: 0.000291\n",
      "Epoch: 155, Loss: 0.000228\n",
      "Epoch: 156, Loss: 0.000288\n",
      "Epoch: 157, Loss: 0.000132\n",
      "Epoch: 158, Loss: 0.000193\n",
      "Epoch: 159, Loss: 0.000144\n",
      "Epoch: 160, Loss: 0.000216\n",
      "Epoch: 161, Loss: 0.000192\n",
      "Epoch: 162, Loss: 0.000352\n",
      "Epoch: 163, Loss: 0.000060\n",
      "Epoch: 164, Loss: 0.000035\n",
      "Epoch: 165, Loss: 0.000080\n",
      "Epoch: 166, Loss: 0.000088\n",
      "Epoch: 167, Loss: 0.000062\n",
      "Epoch: 168, Loss: 0.000093\n",
      "Epoch: 169, Loss: 0.000139\n",
      "Epoch: 170, Loss: 0.000183\n",
      "Epoch: 171, Loss: 0.000205\n",
      "Epoch: 172, Loss: 0.000122\n",
      "Epoch: 173, Loss: 0.000225\n",
      "Epoch: 174, Loss: 0.000071\n",
      "Epoch: 175, Loss: 0.000026\n",
      "Epoch: 176, Loss: 0.000132\n",
      "Epoch: 177, Loss: 0.000029\n",
      "Epoch: 178, Loss: 0.000524\n",
      "Epoch: 179, Loss: 0.000012\n",
      "Epoch: 180, Loss: 0.000209\n",
      "Epoch: 181, Loss: 0.000022\n",
      "Epoch: 182, Loss: 0.000165\n",
      "Epoch: 183, Loss: 0.000209\n",
      "Epoch: 184, Loss: 0.000070\n",
      "Epoch: 185, Loss: 0.000045\n",
      "Epoch: 186, Loss: 0.000132\n",
      "Epoch: 187, Loss: 0.000055\n",
      "Epoch: 188, Loss: 0.000080\n",
      "Epoch: 189, Loss: 0.000104\n",
      "Epoch: 190, Loss: 0.000092\n",
      "Epoch: 191, Loss: 0.000189\n",
      "Epoch: 192, Loss: 0.000174\n",
      "Epoch: 193, Loss: 0.000098\n",
      "Epoch: 194, Loss: 0.000199\n",
      "Epoch: 195, Loss: 0.000249\n",
      "Epoch: 196, Loss: 0.000254\n",
      "Epoch: 197, Loss: 0.000130\n",
      "Epoch: 198, Loss: 0.000158\n",
      "Epoch: 199, Loss: 0.000090\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 200\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.903500\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3737474"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3737474"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sum([p.numel() for p in model.parameters() if p.requires_grad == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1574402"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_model = nn.Sequential(\n",
    "                nn.Linear(3072, 512),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(512, 2),\n",
    "                nn.LogSoftmax(dim=1))\n",
    "\n",
    "sum([p.numel() for p in first_model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1573376"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in nn.Linear(3072, 512).parameters()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3146752"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in nn.Linear(3072, 1024).parameters()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 3072]), torch.Size([1024]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(3072, 1024)\n",
    "\n",
    "linear.weight.shape, linear.bias.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 16, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 3, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = cifar2[0]\n",
    "\n",
    "output = conv(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 16, 30, 30]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.permute(1, 2, 0), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 30, 30])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 32])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    conv.bias.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    conv.weight.fill_(1.0 / 9.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "output = conv(img.unsqueeze(0))\n",
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    conv.weight[:] = torch.tensor([[-1.0, 0.0, 1.0],\n",
    "                                   [-1.0, 0.0, 1.0],\n",
    "                                   [-1.0, 0.0, 1.0]])\n",
    "    conv.bias.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = nn.MaxPool2d(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 16, 16])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pool(img.unsqueeze(0))\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
